{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8866791,"sourceType":"datasetVersion","datasetId":5336452},{"sourceId":8908643,"sourceType":"datasetVersion","datasetId":5356529}],"dockerImageVersionId":30732,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from google.colab import drive\n# drive.mount('/content/drive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TlCsuVB9TiSJ","outputId":"fe53be07-c21f-4469-909c-f0d4ba97dce4","execution":{"iopub.status.busy":"2024-07-08T19:08:34.310382Z","iopub.execute_input":"2024-07-08T19:08:34.311344Z","iopub.status.idle":"2024-07-08T19:08:34.332341Z","shell.execute_reply.started":"2024-07-08T19:08:34.311298Z","shell.execute_reply":"2024-07-08T19:08:34.331430Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:08:34.333974Z","iopub.execute_input":"2024-07-08T19:08:34.334285Z","iopub.status.idle":"2024-07-08T19:08:34.347510Z","shell.execute_reply.started":"2024-07-08T19:08:34.334257Z","shell.execute_reply":"2024-07-08T19:08:34.346399Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# DATASET INITIALIZATION","metadata":{"id":"yq3lXUX8VJgJ"}},{"cell_type":"code","source":"import pandas as pd\n\n# Load training and test data\ntrain_data = pd.read_csv('/kaggle/input/new-dataset/train_FD002.txt', delim_whitespace=True, header=None)\ntest_data = pd.read_csv('/kaggle/input/new-dataset/test_FD002.txt', delim_whitespace=True, header=None)\nrul_data = pd.read_csv('/kaggle/input/new-dataset/RUL_FD002.txt', delim_whitespace=True, header=None)","metadata":{"id":"lvMcQSAFTYmt","execution":{"iopub.status.busy":"2024-07-08T19:13:00.117547Z","iopub.execute_input":"2024-07-08T19:13:00.118008Z","iopub.status.idle":"2024-07-08T19:13:00.777619Z","shell.execute_reply.started":"2024-07-08T19:13:00.117973Z","shell.execute_reply":"2024-07-08T19:13:00.776523Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CiTcmevFqhpz","outputId":"f3d6f1d8-0d8b-4c89-8002-73fb193b420b","execution":{"iopub.status.busy":"2024-07-08T19:13:00.779769Z","iopub.execute_input":"2024-07-08T19:13:00.780131Z","iopub.status.idle":"2024-07-08T19:13:00.786840Z","shell.execute_reply.started":"2024-07-08T19:13:00.780098Z","shell.execute_reply":"2024-07-08T19:13:00.785550Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"(53759, 26)\n(33991, 26)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:13:00.788122Z","iopub.execute_input":"2024-07-08T19:13:00.788761Z","iopub.status.idle":"2024-07-08T19:13:00.804959Z","shell.execute_reply.started":"2024-07-08T19:13:00.788727Z","shell.execute_reply":"2024-07-08T19:13:00.803745Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"0     0\n1     0\n2     0\n3     0\n4     0\n5     0\n6     0\n7     0\n8     0\n9     0\n10    0\n11    0\n12    0\n13    0\n14    0\n15    0\n16    0\n17    0\n18    0\n19    0\n20    0\n21    0\n22    0\n23    0\n24    0\n25    0\ndtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"column_names = [\"engine_id\" , \"time_in_cycles\" , \"altitude\" , \"mach_no\" , \"throttle_angle\" , \"fan_inlet_temp\" , \"LPC_outlet_temp\" , \"HPC_outlet_temp\" , \"LPT_outlet_temp\" , \"fan_inlet_pressure\" , \"bypass_duct_pressure\" , \"HPC_outlet_pressure\" , \"fan_speed\" , \"core_speed\" , \"engine_pressure_ratio\" , \"HPC_outlet_static_pressure\" , \"fuel_ps30_ratio\" , \"corrected_fan_speed\" , \"corrected_core_speed\" , \"bypass_ratio\" , \"burner_fuel_air_ratio\" , \"bleed_enthalpy\" , \"demanded_fan_speed\" , \"demanded_corrected_fan_speed\" , \"HPT_coolant_bleed\" , \"LPT_coolant_bleed\"]\ntrain_data.columns = column_names\ntest_data.columns = column_names","metadata":{"id":"EeLI6DkYT61H","execution":{"iopub.status.busy":"2024-07-08T19:13:00.806580Z","iopub.execute_input":"2024-07-08T19:13:00.806967Z","iopub.status.idle":"2024-07-08T19:13:00.814208Z","shell.execute_reply.started":"2024-07-08T19:13:00.806935Z","shell.execute_reply":"2024-07-08T19:13:00.812925Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_data['RUL'] = train_data.groupby('engine_id')['time_in_cycles'].transform(max) - train_data['time_in_cycles']","metadata":{"id":"HwfBoO2BT9vz","execution":{"iopub.status.busy":"2024-07-08T19:13:00.817600Z","iopub.execute_input":"2024-07-08T19:13:00.818141Z","iopub.status.idle":"2024-07-08T19:13:00.840987Z","shell.execute_reply.started":"2024-07-08T19:13:00.818094Z","shell.execute_reply":"2024-07-08T19:13:00.839888Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# matrix = train_data.corr()\n# print(matrix)","metadata":{"id":"au3bdcdkpTIw","execution":{"iopub.status.busy":"2024-07-08T19:13:00.842180Z","iopub.execute_input":"2024-07-08T19:13:00.842506Z","iopub.status.idle":"2024-07-08T19:13:00.848023Z","shell.execute_reply.started":"2024-07-08T19:13:00.842449Z","shell.execute_reply":"2024-07-08T19:13:00.846839Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# REMOVING OUTLIERS","metadata":{"id":"SVqkwKsUvobm"}},{"cell_type":"code","source":"from scipy import stats\nimport numpy as np\n\n# Calculate Z-scores for sensor measurements and operational settings\nz_scores = np.abs(stats.zscore(train_data.iloc[:, 2:-1]))\n\n# Set a threshold for Z-score\nthreshold = 3\n\n# Identify outliers\noutliers = (z_scores > threshold).any(axis=1)\n\n# Drop outliers\ntrain_data_cleaned = train_data[~outliers]\n","metadata":{"id":"3Q5BnKkNvqmO","execution":{"iopub.status.busy":"2024-07-08T19:13:00.849667Z","iopub.execute_input":"2024-07-08T19:13:00.850010Z","iopub.status.idle":"2024-07-08T19:13:01.451330Z","shell.execute_reply.started":"2024-07-08T19:13:00.849980Z","shell.execute_reply":"2024-07-08T19:13:01.450295Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Calculate Z-scores for test data\nz_scores_test = np.abs(stats.zscore(test_data.iloc[:, 2:]))\n\n# Identify outliers in test data\noutliers_test = (z_scores_test > threshold).any(axis=1)\n\n# Drop outliers from test data\ntest_data_cleaned = test_data[~outliers_test]","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:13:01.452479Z","iopub.execute_input":"2024-07-08T19:13:01.452849Z","iopub.status.idle":"2024-07-08T19:13:01.487164Z","shell.execute_reply.started":"2024-07-08T19:13:01.452819Z","shell.execute_reply":"2024-07-08T19:13:01.486037Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# SCALING","metadata":{"id":"Oj9qxdK3vtTp"}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\n# Normalize the data\nscaler = StandardScaler()\ntrain_data_cleaned.iloc[:, 2:-1] = scaler.fit_transform(train_data_cleaned.iloc[:, 2:-1])\ntest_data_cleaned.iloc[:, 2:] = scaler.transform(test_data_cleaned.iloc[:, 2:])","metadata":{"id":"YXB-ruDaT_bP","execution":{"iopub.status.busy":"2024-07-08T19:13:01.496779Z","iopub.execute_input":"2024-07-08T19:13:01.497116Z","iopub.status.idle":"2024-07-08T19:13:01.647682Z","shell.execute_reply.started":"2024-07-08T19:13:01.497086Z","shell.execute_reply":"2024-07-08T19:13:01.646409Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# LINEAR REGRESSION","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nimport numpy as np\n\n# Select features and target\nfeatures = train_data_cleaned.columns[2:-1]\nX_train_lr = train_data_cleaned[features]\ny_train_lr = train_data_cleaned['RUL']\n\n# Train the Linear Regression model\nmodel_lr = LinearRegression()\nmodel_lr.fit(X_train_lr, y_train_lr)\n\n# Extract the last cycle for each engine in the test set\nlast_cycle_indices_lr = test_data_cleaned.groupby('engine_id')['time_in_cycles'].idxmax()\nX_test_last_cycles_lr = test_data_cleaned.loc[last_cycle_indices_lr, features]\n\n# Make predictions for the last cycles of each engine\ny_pred_last_cycles_lr = model_lr.predict(X_test_last_cycles_lr)\n\n# True RUL values from the provided RUL file\ntrue_rul_lr = rul_data.values.flatten()\n\n# Calculate RMSE and R² Score\nmse_lr = mean_squared_error(true_rul_lr, y_pred_last_cycles_lr)\nrmse_lr = np.sqrt(mse_lr)\nr2_lr = r2_score(true_rul_lr, y_pred_last_cycles_lr)\nmae_lr = mean_absolute_error(true_rul_lr, y_pred_last_cycles_lr)\n\nprint(f'Linear Regression - Root Mean Squared Error (RMSE): {rmse_lr}')\nprint(f'Linear Regression - R² Score: {r2_lr}')\nprint(f'Linear Regression - Mean Absolute Error (MAE): {mae_lr}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3eblEl_pcgfP","outputId":"c72d0196-617e-481f-cd00-af96b7f438e5","execution":{"iopub.status.busy":"2024-07-08T19:13:01.649248Z","iopub.execute_input":"2024-07-08T19:13:01.649752Z","iopub.status.idle":"2024-07-08T19:13:01.968838Z","shell.execute_reply.started":"2024-07-08T19:13:01.649713Z","shell.execute_reply":"2024-07-08T19:13:01.967130Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Linear Regression - Root Mean Squared Error (RMSE): 33.9427252822187\nLinear Regression - R² Score: 0.6016440598064444\nLinear Regression - Mean Absolute Error (MAE): 27.547646570031702\n","output_type":"stream"}]},{"cell_type":"code","source":"X_test_last_cycles_lr.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:13:01.970950Z","iopub.execute_input":"2024-07-08T19:13:01.971670Z","iopub.status.idle":"2024-07-08T19:13:01.983968Z","shell.execute_reply.started":"2024-07-08T19:13:01.971608Z","shell.execute_reply":"2024-07-08T19:13:01.982544Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"(259, 24)"},"metadata":{}}]},{"cell_type":"markdown","source":"# XGBOOST","metadata":{"id":"RWjy5ygNtjO8"}},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# Train the XGBoost model\nmodel_xgb = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=5, learning_rate=0.1)\nmodel_xgb.fit(X_train_lr, y_train_lr)\n\n# Make predictions for the last cycles of each engine\ny_pred_last_cycles_xgb = model_xgb.predict(X_test_last_cycles_lr)\n\n# Calculate RMSE and R² Score\nmse_xgb = mean_squared_error(true_rul_lr, y_pred_last_cycles_xgb)\nrmse_xgb = np.sqrt(mse_xgb)\nr2_xgb = r2_score(true_rul_lr, y_pred_last_cycles_xgb)\nmae_xgb = mean_absolute_error(true_rul_lr, y_pred_last_cycles_xgb)\n\nprint(f'XGBoost - Root Mean Squared Error (RMSE): {rmse_xgb}')\nprint(f'XGBoost - R² Score: {r2_xgb}')\nprint(f'XGBoost - Mean Absolute Error (MAE): {mae_xgb}')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TznzqgcKtZ9w","outputId":"70c68067-91bc-4905-e744-66565a8c3837","execution":{"iopub.status.busy":"2024-07-08T19:13:01.986137Z","iopub.execute_input":"2024-07-08T19:13:01.986989Z","iopub.status.idle":"2024-07-08T19:13:02.842748Z","shell.execute_reply.started":"2024-07-08T19:13:01.986931Z","shell.execute_reply":"2024-07-08T19:13:02.841914Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"XGBoost - Root Mean Squared Error (RMSE): 30.766703389572502\nXGBoost - R² Score: 0.6727046699529016\nXGBoost - Mean Absolute Error (MAE): 23.045762931287978\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# HYPERPARAMETER TUNING","metadata":{"id":"NJ31_BsqMWwg"}},{"cell_type":"code","source":"# from sklearn.model_selection import GridSearchCV\n# import xgboost as xgb\n# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n# import numpy as np\n\n# # Hyperparameter tuning for XGBoost\n# param_grid_xgb = {\n#     'n_estimators': [50, 100, 200],\n#     'max_depth': [3, 5, 7],\n#     'learning_rate': [0.01, 0.1, 0.2],\n#     'subsample': [0.8, 1.0]\n# }\n\n# grid_xgb = GridSearchCV(xgb.XGBRegressor(objective='reg:squarederror'), param_grid_xgb, cv=5, scoring='neg_mean_squared_error')\n# grid_xgb.fit(X_train_lr, y_train_lr)\n\n# print(\"Best parameters for XGBoost:\", grid_xgb.best_params_)\n# print(\"Best RMSE for XGBoost (Cross-Validation):\", np.sqrt(-grid_xgb.best_score_))\n\n# # Train the XGBoost model with best parameters\n# best_model_xgb = grid_xgb.best_estimator_\n\n# # Predictions for training data\n# y_pred_train_xgb = best_model_xgb.predict(X_train_lr)\n\n# # Make predictions for the last cycles of each engine in test data\n# y_pred_last_cycles_xgb = best_model_xgb.predict(X_test_last_cycles_lr)\n\n# # True RUL values from the provided RUL file\n# true_rul_lr = rul_data.values.flatten()\n\n# # # Calculate RMSE, R² Score, and MAE for test data\n# # mse_test_xgb = mean_squared_error(true_rul_lr, y_pred_last_cycles_xgb)\n# # rmse_test_xgb = np.sqrt(mse_test_xgb)\n# # r2_test_xgb = r2_score(true_rul_lr, y_pred_last_cycles_xgb)\n# # mae_test_xgb = mean_absolute_error(true_rul_lr, y_pred_last_cycles_xgb)\n\n# # Calculate RMSE, R² Score, and MAE for train data\n# mse_train_xgb = mean_squared_error(y_train_lr, y_pred_train_xgb)\n# rmse_train_xgb = np.sqrt(mse_train_xgb)\n# r2_train_xgb = r2_score(y_train_lr, y_pred_train_xgb)\n# mae_train_xgb = mean_absolute_error(y_train_lr, y_pred_train_xgb)\n\n# # print(f'XGBoost - Root Mean Squared Error (RMSE) on Test Data: {rmse_test_xgb}')\n# # print(f'XGBoost - R² Score on Test Data: {r2_test_xgb}')\n# # print(f'XGBoost - Mean Absolute Error (MAE) on Test Data: {mae_test_xgb}')\n# print()\n# print(f'XGBoost - Root Mean Squared Error (RMSE) on Train Data: {rmse_train_xgb}')\n# print(f'XGBoost - R² Score on Train Data: {r2_train_xgb}')\n# print(f'XGBoost - Mean Absolute Error (MAE) on Train Data: {mae_train_xgb}')\n","metadata":{"id":"q85n4G4MMlUe","execution":{"iopub.status.busy":"2024-07-08T19:13:02.846319Z","iopub.execute_input":"2024-07-08T19:13:02.846893Z","iopub.status.idle":"2024-07-08T19:16:15.598414Z","shell.execute_reply.started":"2024-07-08T19:13:02.846859Z","shell.execute_reply":"2024-07-08T19:16:15.597527Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Best parameters for XGBoost: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 50, 'subsample': 0.8}\nBest RMSE for XGBoost (Cross-Validation): 44.02973152891171\n\nXGBoost - Root Mean Squared Error (RMSE) on Train Data: 40.46136410097402\nXGBoost - R² Score on Train Data: 0.657925370688508\nXGBoost - Mean Absolute Error (MAE) on Train Data: 29.61741439976453\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Implementing the best parameters","metadata":{}},{"cell_type":"code","source":"# import numpy as np\n# import xgboost as xgb\n# from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n\n# # Best parameters for XGBoost obtained from cross-validation\n# best_params = {\n#     'learning_rate': 0.1,\n#     'max_depth': 7,\n#     'n_estimators': 50,\n#     'subsample': 0.8\n# }\n\n# # Train the XGBoost model with the best parameters\n# model_xgb = xgb.XGBRegressor(objective='reg:squarederror', **best_params)\n# model_xgb.fit(X_train_lr, y_train_lr)\n\n# # Predictions for training data\n# y_pred_train_xgb = model_xgb.predict(X_train_lr)\n\n# # Make predictions for the last cycles of each engine in test data\n# y_pred_last_cycles_xgb = model_xgb.predict(X_test_last_cycles_lr)\n\n# # True RUL values from the provided RUL file\n# true_rul_lr = rul_data.values.flatten()\n\n# # Calculate RMSE, R² Score, and MAE for test data\n# mse_test_xgb = mean_squared_error(true_rul_lr, y_pred_last_cycles_xgb)\n# rmse_test_xgb = np.sqrt(mse_test_xgb)\n# r2_test_xgb = r2_score(true_rul_lr, y_pred_last_cycles_xgb)\n# mae_test_xgb = mean_absolute_error(true_rul_lr, y_pred_last_cycles_xgb)\n\n# # Calculate RMSE, R² Score, and MAE for train data\n# mse_train_xgb = mean_squared_error(y_train_lr, y_pred_train_xgb)\n# rmse_train_xgb = np.sqrt(mse_train_xgb)\n# r2_train_xgb = r2_score(y_train_lr, y_pred_train_xgb)\n# mae_train_xgb = mean_absolute_error(y_train_lr, y_pred_train_xgb)\n\n# print(f'XGBoost - Root Mean Squared Error (RMSE) on Test Data: {rmse_test_xgb}')\n# print(f'XGBoost - R² Score on Test Data: {r2_test_xgb}')\n# print(f'XGBoost - Mean Absolute Error (MAE) on Test Data: {mae_test_xgb}')\n# print()\n# print(f'XGBoost - Root Mean Squared Error (RMSE) on Train Data: {rmse_train_xgb}')\n# print(f'XGBoost - R² Score on Train Data: {r2_train_xgb}')\n# print(f'XGBoost - Mean Absolute Error (MAE) on Train Data: {mae_train_xgb}')\n\n# print()\n\n# # Best RMSE from cross-validation\n# best_rmse_cv = 44.02973152891171\n# print(f'Best RMSE for XGBoost (Cross-Validation): {best_rmse_cv}')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:16:15.599806Z","iopub.execute_input":"2024-07-08T19:16:15.600324Z","iopub.status.idle":"2024-07-08T19:16:16.190064Z","shell.execute_reply.started":"2024-07-08T19:16:15.600292Z","shell.execute_reply":"2024-07-08T19:16:16.189069Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"XGBoost - Root Mean Squared Error (RMSE) on Test Data: 30.214729064790482\nXGBoost - R² Score on Test Data: 0.6843430993934015\nXGBoost - Mean Absolute Error (MAE) on Test Data: 22.28316208754727\n\nXGBoost - Root Mean Squared Error (RMSE) on Train Data: 40.46136410097402\nXGBoost - R² Score on Train Data: 0.657925370688508\nXGBoost - Mean Absolute Error (MAE) on Train Data: 29.61741439976453\n\nBest RMSE for XGBoost (Cross-Validation): 44.02973152891171\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# BFE with XGBoost","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\nimport numpy as np\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:23:30.446165Z","iopub.execute_input":"2024-07-08T19:23:30.446978Z","iopub.status.idle":"2024-07-08T19:23:30.452403Z","shell.execute_reply.started":"2024-07-08T19:23:30.446938Z","shell.execute_reply":"2024-07-08T19:23:30.451137Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Function to calculate model performance\ndef calculate_performance(model, X_train, y_train, X_test, y_test):\n    model.fit(X_train, y_train)\n    y_pred = model.predict(X_test)\n    mse = mean_squared_error(y_test, y_pred)\n    rmse= np.sqrt(mse)\n    r2 = r2_score(y_test, y_pred)\n    mae = mean_absolute_error(y_test, y_pred)\n    return rmse, mae, r2","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:23:30.685334Z","iopub.execute_input":"2024-07-08T19:23:30.685711Z","iopub.status.idle":"2024-07-08T19:23:30.692247Z","shell.execute_reply.started":"2024-07-08T19:23:30.685681Z","shell.execute_reply":"2024-07-08T19:23:30.690989Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Backward Feature Elimination for XGBoost\ndef backward_feature_elimination_xgb(X_train, y_train, X_test, y_test):\n    features = X_train.columns.tolist()\n    best_features = features[:]\n    best_rmse = float('inf')\n    best_mae = float('inf')\n    best_r2 = float('-inf')\n    \n    while len(features) > 1:\n        scores = {}\n        for feature in features:\n            remaining_features = [f for f in features if f != feature]\n            X_train_subset = X_train[remaining_features]\n            X_test_subset = X_test[remaining_features]\n            \n            model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, max_depth=5, learning_rate=0.1)\n            rmse, mae, r2 = calculate_performance(model, X_train_subset, y_train, X_test_subset, y_test)\n            scores[feature] = (rmse, mae, r2)\n        \n        # Find the worst feature to remove\n        worst_feature = max(scores, key=lambda k: scores[k][0])\n        worst_rmse, worst_mae, worst_r2 = scores[worst_feature]\n        features.remove(worst_feature)\n        \n        if worst_rmse < best_rmse:\n            best_rmse = worst_rmse\n            best_mae = worst_mae\n            best_r2 = worst_r2\n            best_features = features[:]\n        else:\n            break\n    \n    return best_features, best_rmse, best_mae, best_r2","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:23:30.980125Z","iopub.execute_input":"2024-07-08T19:23:30.980599Z","iopub.status.idle":"2024-07-08T19:23:30.992315Z","shell.execute_reply.started":"2024-07-08T19:23:30.980560Z","shell.execute_reply":"2024-07-08T19:23:30.990932Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Prepare the data\nfeatures = train_data_cleaned.columns[2:-1]\nX_train = train_data_cleaned[features]\ny_train = train_data_cleaned['RUL']\nX_test = test_data_cleaned.loc[last_cycle_indices_lr, features]\ny_test = rul_data.values.flatten()\n\n# Perform BFE with XGBoost\nselected_features, best_rmse, best_mae, best_r2 = backward_feature_elimination_xgb(X_train, y_train, X_test, y_test)\nprint(f'XGBoost - Selected features: {selected_features}')\nprint(f'XGBoost - Best RMSE: {best_rmse}')\nprint(f'XGBoost - Best MAE: {best_mae}')\nprint(f'XGBoost - Best R²: {best_r2}')","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:23:31.322677Z","iopub.execute_input":"2024-07-08T19:23:31.323081Z","iopub.status.idle":"2024-07-08T19:24:02.743472Z","shell.execute_reply.started":"2024-07-08T19:23:31.323049Z","shell.execute_reply":"2024-07-08T19:24:02.742476Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"XGBoost - Selected features: ['altitude', 'mach_no', 'throttle_angle', 'fan_inlet_temp', 'LPC_outlet_temp', 'HPC_outlet_temp', 'LPT_outlet_temp', 'fan_inlet_pressure', 'bypass_duct_pressure', 'HPC_outlet_pressure', 'fan_speed', 'core_speed', 'engine_pressure_ratio', 'HPC_outlet_static_pressure', 'fuel_ps30_ratio', 'corrected_fan_speed', 'corrected_core_speed', 'burner_fuel_air_ratio', 'bleed_enthalpy', 'demanded_fan_speed', 'demanded_corrected_fan_speed', 'HPT_coolant_bleed', 'LPT_coolant_bleed']\nXGBoost - Best RMSE: 31.76500731701249\nXGBoost - Best MAE: 24.06389452522786\nXGBoost - Best R²: 0.6511202208322515\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data_cleaned.shape","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:25:07.999581Z","iopub.execute_input":"2024-07-08T19:25:08.000513Z","iopub.status.idle":"2024-07-08T19:25:08.007982Z","shell.execute_reply.started":"2024-07-08T19:25:08.000444Z","shell.execute_reply":"2024-07-08T19:25:08.006721Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"(53759, 27)"},"metadata":{}}]},{"cell_type":"code","source":"print(len(selected_features))","metadata":{"execution":{"iopub.status.busy":"2024-07-08T19:24:47.693799Z","iopub.execute_input":"2024-07-08T19:24:47.694519Z","iopub.status.idle":"2024-07-08T19:24:47.700064Z","shell.execute_reply.started":"2024-07-08T19:24:47.694468Z","shell.execute_reply":"2024-07-08T19:24:47.698755Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"23\n","output_type":"stream"}]}]}