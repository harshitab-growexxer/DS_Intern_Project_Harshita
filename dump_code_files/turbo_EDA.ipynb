{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Hnz9b7TGXsPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "rhTIvo7lgm_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cb3B_iWITAT_"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/test_turbo_with_rul.csv')\n",
        "train = pd.read_csv('/content/drive/MyDrive/train_turbo_with_rul.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.shape"
      ],
      "metadata": {
        "id": "noim7V16gyhP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "metadata": {
        "id": "vNHL5n-ZM-j5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "id": "Vw8_Zf9UM_TP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.columns"
      ],
      "metadata": {
        "id": "NN6dMEsgNCDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()"
      ],
      "metadata": {
        "id": "ZuhpHjenNHbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train.drop(['index', 'source'], axis=1)"
      ],
      "metadata": {
        "id": "gXfDfYElN_16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "id": "mFuRQu03OJEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.describe().T"
      ],
      "metadata": {
        "id": "nl7bpOZjOMyt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test.describe().T"
      ],
      "metadata": {
        "id": "uRHKDn8aORig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_time_cycles=train[['engine_no', 'cycles_completed']].groupby('engine_no').max()\n",
        "plt.figure(figsize=(20,50))\n",
        "ax=max_time_cycles['cycles_completed'].plot(kind='barh',width=0.8, stacked=True,align='center')\n",
        "plt.title('Turbofan Engines LifeTime',fontweight='bold',size=30)\n",
        "plt.xlabel('Time cycle',fontweight='bold',size=20)\n",
        "plt.xticks(size=15)\n",
        "plt.ylabel('unit',fontweight='bold',size=20)\n",
        "plt.yticks(size=15)\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CCghQgW9O_mH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Distribution of maximum time cycles\n",
        "sns.displot(max_time_cycles['cycles_completed'],kde=True,bins=20,height=6,aspect=2)\n",
        "plt.xlabel('max time cycle')"
      ],
      "metadata": {
        "id": "RNNCAqE2es3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.heatmap(train.corr(),annot=True,cmap='RdYlGn')\n",
        "# fig=plt.gcf()\n",
        "# fig.set_size_inches(20,20)\n",
        "# plt.show()\n",
        "\n",
        "matrix = train.corr()\n",
        "print(matrix)"
      ],
      "metadata": {
        "id": "TEEn6A6ke2zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the correlation matrix\n",
        "corr = train.corr()\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "f, ax = plt.subplots(figsize=(10, 10))\n",
        "cmap = sns.diverging_palette(230, 10, as_cmap=True)\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "metadata": {
        "id": "81qW5uMK2Y9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "id": "9mkHlLiu_-zG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Your column names\n",
        "column_names = ['engine_no', 'cycles_completed', 'altitude', 'mach_no',\n",
        "                'throttle_angle', 'fan_inlet_temp', 'lpc_outlet_temp',\n",
        "                'hpc_outlet_temp', 'lpt_outlet_temp', 'fan_inlet_pressure',\n",
        "                'bypass_duct_pressure', 'hpc_outlet_pressure', 'fan_speed',\n",
        "                'core_speed', 'engine_pressure_ratio', 'hpc_outlet_static_pressure',\n",
        "                'fuel_ps30_ratio', 'corrected_fan_speed', 'corrected_core_speed',\n",
        "                'bypass_ratio', 'burner_fuel_air_ratio', 'bleed_enthalpy',\n",
        "                'demanded_fan_speed', 'demanded_corrected_fan_speed',\n",
        "                'hpt_coolant_bleed', 'lpt_coolant_bleed', 'RUL']\n",
        "\n",
        "# Define the Sensor dictionary with the column names\n",
        "Sensor_dictionary = {\n",
        "    'fan_inlet_temp': \"(Fan inlet temperature) (◦R)\",\n",
        "    'lpc_outlet_temp': \"(LPC outlet temperature) (◦R)\",\n",
        "    'hpc_outlet_temp': \"(HPC outlet temperature) (◦R)\",\n",
        "    'lpt_outlet_temp': \"(LPT outlet temperature) (◦R)\",\n",
        "    'fan_inlet_pressure': \"(Fan inlet Pressure) (psia)\",\n",
        "    'bypass_duct_pressure': \"(bypass-duct pressure) (psia)\",\n",
        "    'hpc_outlet_pressure': \"(HPC outlet pressure) (psia)\",\n",
        "    'fan_speed': \"(Physical fan speed) (rpm)\",\n",
        "    'core_speed': \"(Physical core speed) (rpm)\",\n",
        "    'engine_pressure_ratio': \"(Engine pressure ratio(P50/P2))\",\n",
        "    'hpc_outlet_static_pressure': \"(HPC outlet Static pressure) (psia)\",\n",
        "    'fuel_ps30_ratio': \"(Ratio of fuel flow to Ps30) (pps/psia)\",\n",
        "    'corrected_fan_speed': \"(Corrected fan speed) (rpm)\",\n",
        "    'corrected_core_speed': \"(Corrected core speed) (rpm)\",\n",
        "    'bypass_ratio': \"(Bypass Ratio)\",\n",
        "    'burner_fuel_air_ratio': \"(Burner fuel-air ratio)\",\n",
        "    'bleed_enthalpy': \"(Bleed Enthalpy)\",\n",
        "    'demanded_fan_speed': \"(Required fan speed)\",\n",
        "    'demanded_corrected_fan_speed': \"(Required fan conversion speed)\",\n",
        "    'hpt_coolant_bleed': \"(High-pressure turbines Cool air flow)\",\n",
        "    'lpt_coolant_bleed': \"(Low-pressure turbines Cool air flow)\"\n",
        "}\n",
        "\n",
        "def plot_signal(df, Sensor_dic, signal_name):\n",
        "    plt.figure(figsize=(13, 5))\n",
        "    for i in df['engine_no'].unique():\n",
        "        if (i % 10 == 0):  # For a better visualisation, we plot the sensors signals of 20 units only\n",
        "            plt.plot('RUL', signal_name, data=df[df['engine_no'] == i].rolling(10).mean())\n",
        "\n",
        "    plt.xlim(250, 0)  # Reverse the x-axis so RUL counts down to zero\n",
        "    plt.xticks(np.arange(0, 300, 25))\n",
        "    plt.ylabel(Sensor_dic[signal_name])\n",
        "    plt.xlabel('Remaining Useful Life')\n",
        "    plt.show()\n",
        "\n",
        "# Assuming your data is in a DataFrame named train\n",
        "for signal in Sensor_dictionary.keys():\n",
        "    try:\n",
        "        plot_signal(train, Sensor_dictionary, signal)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not plot signal {signal}: {e}\")"
      ],
      "metadata": {
        "id": "3WNxnvkp_ykA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of sensor names from your dataset\n",
        "sensor_names = [\n",
        "    'fan_inlet_temp', 'lpc_outlet_temp', 'hpc_outlet_temp', 'lpt_outlet_temp',\n",
        "    'fan_inlet_pressure', 'bypass_duct_pressure', 'hpc_outlet_pressure', 'fan_speed',\n",
        "    'core_speed', 'engine_pressure_ratio', 'hpc_outlet_static_pressure', 'fuel_ps30_ratio',\n",
        "    'corrected_fan_speed', 'corrected_core_speed', 'bypass_ratio', 'burner_fuel_air_ratio',\n",
        "    'bleed_enthalpy', 'demanded_fan_speed', 'demanded_corrected_fan_speed',\n",
        "    'hpt_coolant_bleed', 'lpt_coolant_bleed'\n",
        "]\n",
        "\n",
        "# Plot boxplots for each sensor\n",
        "for sensor in sensor_names:\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    plt.boxplot(train[sensor].dropna(), vert=False)  # Use dropna() to handle any missing values\n",
        "    plt.title(f'Boxplot of {sensor}')\n",
        "    plt.xlabel(sensor)\n",
        "    plt.show()\n",
        "\n",
        "# # Plot boxplots for each sensor\n",
        "# for sensor in sensor_names:\n",
        "#     plt.figure(figsize=(15, 8))\n",
        "#     plt.boxplot(test[sensor].dropna(), vert=False)  # Use dropna() to handle any missing values\n",
        "#     plt.title(f'Boxplot of {sensor}')\n",
        "#     plt.xlabel(sensor)\n",
        "#     plt.show()"
      ],
      "metadata": {
        "id": "CBlK-oxlC4Nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engine_counts = train['engine_no'].value_counts().reset_index()\n",
        "engine_counts.columns = ['engine', 'count']\n",
        "\n",
        "# # Drawing bars with seaborn\n",
        "# plt.figure(figsize=(22, 12))\n",
        "# sns.barplot(x='count', y='engine', data=engine_counts)\n",
        "# plt.title('Count of Each Engine')\n",
        "# plt.xlabel('Count')\n",
        "# plt.ylabel('Engine Number')\n",
        "# plt.xticks(rotation=90)\n",
        "# plt.show()\n",
        "\n",
        "# Plotting with seaborn countplot\n",
        "plt.figure(figsize=(22, 20))\n",
        "sns.countplot(y='engine_no', data=train, order=engine_counts['engine'])\n",
        "plt.title('Count of Each Engine')\n",
        "plt.xlabel('Count')\n",
        "plt.ylabel('Engine Number')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fLxk_9vxC4wW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the maximum 'cycle' value for each engine\n",
        "max_cycle_per_engine = train.groupby('engine_no')['cycles_completed'].max().reset_index()\n",
        "\n",
        "# Rename columns\n",
        "max_cycle_per_engine.columns = ['engine_no', 'max_cycle']\n",
        "\n",
        "# Sort by 'engine' column\n",
        "max_cycle_per_engine = max_cycle_per_engine.sort_values('engine_no')\n",
        "\n",
        "# # Drawing bar graphs\n",
        "# plt.figure(figsize=(20, 15))\n",
        "# plt.bar(max_cycle_per_engine['engine_no'].astype(str), max_cycle_per_engine['max_cycle'])\n",
        "# plt.title('Maximum Cycle per Engine')\n",
        "# plt.xlabel('Engine Number')\n",
        "# plt.ylabel('Maximum Cycle')\n",
        "# plt.xticks(rotation=90)\n",
        "# plt.show()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Define the bins and the corresponding labels\n",
        "bins = [0, 50, 100, 150, 200, 250, 300, 350, 400]\n",
        "labels = ['0-50', '51-100', '101-150', '151-200', '201-250', '251-300', '301-350', '351-400']\n",
        "\n",
        "# Create a new column 'cycle_bin' to categorize 'max_cycle' into bins\n",
        "max_cycle_per_engine['cycle_bin'] = pd.cut(max_cycle_per_engine['max_cycle'], bins=bins, labels=labels)\n",
        "\n",
        "# Count the number of engines in each bin\n",
        "bin_counts = max_cycle_per_engine['cycle_bin'].value_counts().sort_index()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Drawing bar graphs for binned data\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.bar(bin_counts.index, bin_counts.values)\n",
        "plt.title('Number of Engines in Each Cycle Range')\n",
        "plt.xlabel('Cycle Range')\n",
        "plt.ylabel('Number of Engines')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zeQU4i_Djyis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML"
      ],
      "metadata": {
        "id": "ShXrD8vTtnWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.columns"
      ],
      "metadata": {
        "id": "IiikDgmJz9mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "index_names = ['engine_no', 'cycles_completed']"
      ],
      "metadata": {
        "id": "U6i3kOwk0C6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "drop_labels = index_names\n",
        "X_train=train.drop(columns=drop_labels).copy()\n",
        "X_train, X_test, y_train, y_test=train_test_split(X_train,X_train['RUL'], test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "NgWQBjV9tqoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "#Droping the target variable\n",
        "X_train.drop(columns=['RUL'], inplace=True)\n",
        "X_test.drop(columns=['RUL'], inplace=True)\n",
        "\n",
        "#Scaling X_train and X_test\n",
        "X_train_s=scaler.fit_transform(X_train)\n",
        "X_test_s=scaler.fit_transform(X_test)\n",
        "\n",
        "\n",
        "# Prepare validation data\n",
        "drop_labels_valid = index_names + ['remaining_useful_life', 'index_y', 'source', 'index_x']\n",
        "X_valid = test.drop(columns=drop_labels_valid)\n",
        "X_valid_s = scaler.transform(X_valid)\n",
        "y_valid = test['remaining_useful_life']\n"
      ],
      "metadata": {
        "id": "mcrnaDESuCaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid"
      ],
      "metadata": {
        "id": "atWnHgICuezE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_valid"
      ],
      "metadata": {
        "id": "at7zDqr71SWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_valid_s.shape)\n",
        "print(y_valid.shape)"
      ],
      "metadata": {
        "id": "kUGwBuGQufVr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Train linear regression model\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train_s, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_test = lr.predict(X_test_s)\n",
        "\n",
        "# Evaluate the model\n",
        "mse_test = mean_squared_error(y_test, y_pred_test)\n",
        "r2_test = r2_score(y_test, y_pred_test)\n",
        "\n",
        "# Calculate RMSE for the test set\n",
        "rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
        "print(f\"Test RMSE: {rmse_test}\")\n",
        "\n",
        "print(f\"Test Mean Squared Error: {mse_test}\")\n",
        "print()\n",
        "print(f\"Test R-squared: {r2_test}\")"
      ],
      "metadata": {
        "id": "lnOOt3wcuh4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the validation set\n",
        "y_pred_valid = lr.predict(X_valid_s)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "mse_valid = mean_squared_error(y_valid, y_pred_valid)\n",
        "r2_valid = r2_score(y_valid, y_pred_valid)\n",
        "\n",
        "# Calculate RMSE for the validation set\n",
        "rmse_valid = np.sqrt(mean_squared_error(y_valid, y_pred_valid))\n",
        "print(f\"Validation RMSE: {rmse_valid}\")\n",
        "\n",
        "print(f\"Validation Mean Squared Error: {mse_valid}\")\n",
        "\n",
        "print(f\"Validation R-squared: {r2_valid}\")"
      ],
      "metadata": {
        "id": "jOgzkwNyz4ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7mssG8aCAKSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# REMOVING OUTLIERS"
      ],
      "metadata": {
        "id": "o6rdpCz-NbOh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "# Assuming your dataframe is named 'train'\n",
        "# Calculate Z-scores\n",
        "z_scores = np.abs(stats.zscore(train.drop(columns=index_names)))\n",
        "\n",
        "# Set a threshold for Z-scores\n",
        "threshold = 3\n",
        "\n",
        "# Identify rows to drop\n",
        "outliers = np.where(z_scores > threshold)\n",
        "\n",
        "# Create a mask to identify outliers\n",
        "mask = (z_scores < threshold).all(axis=1)\n",
        "\n",
        "# Filter out outliers\n",
        "train_clean = train[mask]\n",
        "\n",
        "print(\"Shape of dataset before dropping outliers:\", train.shape)\n",
        "print(\"Shape of dataset after dropping outliers:\", train_clean.shape)\n",
        "\n",
        "# Now, use 'train_clean' for further processing\n"
      ],
      "metadata": {
        "id": "hYG1sLblNdIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the cleaned dataset\n",
        "X_train_clean, X_test_clean, y_train_clean, y_test_clean = train_test_split(\n",
        "    train_clean.drop(columns=['RUL'] + index_names),\n",
        "    train_clean['RUL'],\n",
        "    test_size=0.3,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Scaling the features\n",
        "scaler = MinMaxScaler()\n",
        "X_train_s_clean = scaler.fit_transform(X_train_clean)\n",
        "X_test_s_clean = scaler.transform(X_test_clean)\n",
        "\n",
        "# Train and evaluate the model\n",
        "lr_clean = LinearRegression()\n",
        "lr_clean.fit(X_train_s_clean, y_train_clean)\n",
        "y_pred_test_clean = lr_clean.predict(X_test_s_clean)\n",
        "\n",
        "# Calculate RMSE and R-squared for the test set\n",
        "mse_test_clean = mean_squared_error(y_test_clean, y_pred_test_clean)\n",
        "r2_test_clean = r2_score(y_test_clean, y_pred_test_clean)\n",
        "rmse_test_clean = np.sqrt(mse_test_clean)\n",
        "\n",
        "print(f\"Test RMSE after cleaning: {rmse_test_clean}\")\n",
        "print(f\"Test R-squared after cleaning: {r2_test_clean}\")\n",
        "\n",
        "# For validation, repeat the same steps as before with the cleaned training data\n",
        "# and use the original validation data\n",
        "X_valid_s_clean = scaler.transform(X_valid)\n",
        "y_pred_valid_clean = lr_clean.predict(X_valid_s_clean)\n",
        "\n",
        "mse_valid_clean = mean_squared_error(y_valid, y_pred_valid_clean)\n",
        "r2_valid_clean = r2_score(y_valid, y_pred_valid_clean)\n",
        "rmse_valid_clean = np.sqrt(mse_valid_clean)\n",
        "\n",
        "print(f\"Validation RMSE after cleaning: {rmse_valid_clean}\")\n",
        "print(f\"Validation R-squared after cleaning: {r2_valid_clean}\")\n"
      ],
      "metadata": {
        "id": "NdH1BECANjfk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}